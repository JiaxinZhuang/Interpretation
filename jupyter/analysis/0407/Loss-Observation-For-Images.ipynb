{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "1. Comparision for batch of images, need to specify the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms                                                                                                                                        \n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 600\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../src/\")\n",
    "sys.path.append(\"../../\")\n",
    "import model\n",
    "from datasets import imagenet\n",
    "from loss import FileterLoss\n",
    "import config\n",
    "#from utils.function import init_logging, init_environment, preprocess_image,\\\n",
    "#         recreate_image, get_lr, save_image\n",
    "from aux.utils import obtain_features_map, load_imgs, zscore, extract_valid\n",
    "from aux.visualization import visualize_features_map_for_comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of new dataset is :30\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "reverse_mean = [-0.485, -0.456, -0.406]\n",
    "reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "train_transform = None\n",
    "train_transform = transforms.Compose([                                                                                                                                \n",
    "    transforms.Resize((224, 224), interpolation=Image.BILINEAR),                                                                                              \n",
    "    transforms.ToTensor(),                                                                                                                                            \n",
    "    transforms.Normalize(mean, std)                                                                                                                                   \n",
    "       ])         \n",
    "trainset = imagenet.ImageNet(root=\"/media/lincolnzjx/HardDisk/Datasets/\", is_train=True, transform=train_transform)\n",
    "\n",
    "trainset.set_data([950], 30)\n",
    "imgs_path = []                                                                                                                                                            \n",
    "images = []\n",
    "labels = []\n",
    "for img, label, img_path in trainset:                                                                                                                                     \n",
    "    images.append(img.unsqueeze(0))                                                                                                                                       \n",
    "    labels.append(label)                                                                                                                                                  \n",
    "    imgs_path.append(img_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack\"\n",
    "################### Hyper-Parameter #######################\n",
    "exp = \"2204\"\n",
    "epoch = \"49900\"\n",
    "##########################################################\n",
    "ab_path = os.path.join(save_dir, exp, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Use original fc\n",
      "Resume from model from exp: 037 at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume = \"037-0\"\n",
    "model_dir = \"/home/lincolnzjx/Desktop/Interpretation/saved/models\"\n",
    "backbone = \"vgg16\"\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = model.Network(backbone=backbone, num_classes=1000)\n",
    "net.to(device)\n",
    "# resume from model\n",
    "resume_exp = resume.split(\"-\")[0]\n",
    "resume_epoch = resume.split(\"-\")[1]\n",
    "print(\"Resume from model from exp: {} at epoch {}\".format(resume_exp, resume_epoch))\n",
    "resume_path = os.path.join(model_dir, str(resume_exp), str(resume_epoch))\n",
    "ckpt = torch.load(resume_path, map_location=device)\n",
    "net.load_state_dict(ckpt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10061.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10068.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10110.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10134.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10162.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10166.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10178.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10179.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10184.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10192.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10204.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10205.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_1021.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10213.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10217.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10232.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10258.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10290.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10305.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10345.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10358.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10379.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10420.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10425.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10436.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10465.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10482.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10485.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10491.JPEG\n",
      "Load from /home/lincolnzjx/Desktop/Interpretation/jupyter/analysis/0407/pack/2204/49900/n07747607_10545.JPEG\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "optimized_data, valid_imgs_path, valid_imgs_index = load_imgs(ab_path, imgs_path, non_exists_ok=True)\n",
    "valid_imgs, valid_labels = extract_valid(images, labels, valid_imgs_index)\n",
    "optimized_data = zscore(optimized_data, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to device\n",
    "opt_image = torch.from_numpy(optimized_data).to(device)\n",
    "original_image = torch.cat(valid_imgs, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layer = 6\n",
    "selected_filter = 19\n",
    "mode = \"keep\"\n",
    "inter = False\n",
    "rho = 0\n",
    "regularization = \"L1\"\n",
    "smoothing = \"None\"\n",
    "regular_ex = 2\n",
    "alpha = 100\n",
    "beta = 1\n",
    "gamma = 100\n",
    "delta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.Calculate Loss\n",
    "criterion = FileterLoss(net, selected_layer, selected_filter, mode,\n",
    "                        inter=inter, rho=rho,\n",
    "                        regularization=regularization,\n",
    "                        smoothing=smoothing, p=regular_ex, _print=print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1260, device='cuda:0')\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "selected_filter_loss, rest_fileter_loss, regularization_loss,  \\\n",
    "      smoothing_loss = criterion(opt_image, original_image)\n",
    "loss = alpha * selected_filter_loss + beta * rest_fileter_loss + \\\n",
    "    gamma * regularization_loss + delta * smoothing_loss\n",
    "print(selected_filter_loss)\n",
    "print(rest_fileter_loss)\n",
    "print(regularization_loss)\n",
    "print(smoothing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
