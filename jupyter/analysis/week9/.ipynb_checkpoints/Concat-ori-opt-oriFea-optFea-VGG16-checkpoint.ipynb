{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T09:46:11.314179Z",
     "start_time": "2020-06-13T09:46:11.301627Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T09:46:12.289937Z",
     "start_time": "2020-06-13T09:46:11.315273Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms                                                                                                                                        \n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 600\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../src/\")\n",
    "sys.path.append(\"../../\")\n",
    "import model\n",
    "from datasets import imagenet\n",
    "import config\n",
    "from aux.utils import obtain_features_map, load_imgs, zscore, extract_valid\n",
    "from aux.visualization import visualize_features_map\n",
    "from utils.visualizations.visualize import concat_imgs, preprocess_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T09:46:12.312021Z",
     "start_time": "2020-06-13T09:46:12.291164Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(exp, selected_layer, selected_filter, class_index=950):\n",
    "    num_class = 30\n",
    "    class_index = class_index\n",
    "    print(\"=> class index: {}\".format(class_index))\n",
    "    backbone = \"vgg16\"\n",
    "    resume = \"037-0\"\n",
    "    color_map = \"jet\"\n",
    "    model_dir = \"/home/lincolnzjx/Desktop/Interpretation/saved/models\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    ## Load modal from dict\n",
    "    \n",
    "    # model\n",
    "    net = model.Network(backbone=backbone, num_classes=1000, \n",
    "                        selected_layer=selected_layer)\n",
    "    net.to(device)\n",
    "    \n",
    "    # resume from model\n",
    "    resume_exp = resume.split(\"-\")[0]\n",
    "    resume_epoch = resume.split(\"-\")[1]\n",
    "    print(\"Resume from model from exp: {} at epoch {}\".format(resume_exp, resume_epoch))\n",
    "    resume_path = os.path.join(model_dir, str(resume_exp), str(resume_epoch))\n",
    "    ckpt = torch.load(resume_path, map_location=device)\n",
    "    net.load_state_dict(ckpt, strict=False) \n",
    "    \n",
    "    summary(net, (3, 224, 224))\n",
    "    \n",
    "    ## Load Original Data \n",
    "    \n",
    "    # Load data\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    train_transform = None\n",
    "    train_transform = transforms.Compose([                                                                                                                                \n",
    "        transforms.Resize((224, 224), interpolation=Image.BILINEAR),                                                                                              \n",
    "        transforms.ToTensor(),                                                                                                                                            \n",
    "        #transforms.Normalize(mean, std)                                                                                                                                   \n",
    "           ])         \n",
    "    trainset = imagenet.ImageNet(root=\"/media/lincolnzjx/HardDisk/Datasets/\", \n",
    "                                 is_train=True, transform=train_transform)\n",
    "    \n",
    "    trainset.set_data([class_index], num_class)\n",
    "    imgs_path = []                                                                                                                                                            \n",
    "    images = []\n",
    "    labels = []\n",
    "    for img, label, img_path in trainset:                                                                                                                                     \n",
    "        images.append(img.unsqueeze(0))                                                                                                                                       \n",
    "        labels.append(label)                                                                                                                                                  \n",
    "        imgs_path.append(img_path)  \n",
    "    \n",
    "    ## Create some need path\n",
    "    \n",
    "    save_dir = \"../../../saved/pack/\"\n",
    "    ################### Hyper-Parameter #######################\n",
    "    # exp = resume_exp\n",
    "    # epoch = resume_epoch\n",
    "    ##########################################################\n",
    "    ab_path = os.path.join(save_dir, exp)\n",
    "    \n",
    "    index2image = {index: item.split(\"/\")[-1].split(\".\")[0] for index, item in enumerate(imgs_path)}\n",
    "    index2image\n",
    "    \n",
    "    images_cpu = np.array([image.detach().clone().cpu().numpy().squeeze() for image in images])\n",
    "    \n",
    "    # Load image\n",
    "    # ext may be different.\n",
    "    optimized_data, valid_imgs_path, valid_imgs_index = load_imgs(ab_path, imgs_path, non_exists_ok=True, ext=\".png\")\n",
    "    valid_imgs, valid_labels = extract_valid(images, labels, valid_imgs_index)\n",
    "    optimized_data_zscore = zscore(optimized_data, mean, std)\n",
    "    images_zscore = zscore(images_cpu, mean, std)\n",
    "    \n",
    "    # Move to device\n",
    "    opt_image = torch.from_numpy(optimized_data_zscore).to(device)\n",
    "    original_image = torch.from_numpy(images_zscore).to(device)\n",
    "    \n",
    "    ## Obtain feature from conv layers.\n",
    "    \n",
    "    ori_activation_maps = net.get_activation_maps(original_image, \n",
    "                                                  selected_layer=selected_layer)[0]\n",
    "    opt_activation_maps = net.get_activation_maps(opt_image, \n",
    "                                                  selected_layer=selected_layer)[0]\n",
    "    \n",
    "    images_cpu_p, optimized_data_cpu, ori_activation_maps_cpu, \\\n",
    "       opt_activation_maps_cpu, optimized_data_cpu_scale, \\\n",
    "       diff_activation_maps_cpu,\\\n",
    "       ori_activation_maps_cpu_n1e1, opt_activation_maps_cpu_n1e1, \\\n",
    "       diff_activation_maps_cpu_n1e1,\\\n",
    "       ori_activation_maps_cpu_n2e1, opt_activation_maps_cpu_n2e1, \\\n",
    "       diff_activation_maps_cpu_n2e1,\\\n",
    "       ori_activation_maps_cpu_n4e1, opt_activation_maps_cpu_n4e1,\\\n",
    "       diff_activation_maps_cpu_n4e1 = \\\n",
    "       preprocess_arrays(images_cpu, optimized_data,\n",
    "                         ori_activation_maps, opt_activation_maps,\n",
    "                         selected_filter, color_map=color_map)\n",
    "    concated_imgs, concated_fms, concated_imgs_fms = concat_imgs(\n",
    "        images_cpu_p, optimized_data_cpu,\n",
    "        ori_activation_maps_cpu, opt_activation_maps_cpu,\n",
    "        optimized_data_cpu_scale, diff_activation_maps_cpu,\n",
    "        ori_activation_maps_cpu_n1e1, opt_activation_maps_cpu_n1e1,\n",
    "        diff_activation_maps_cpu_n1e1,\n",
    "        ori_activation_maps_cpu_n2e1, opt_activation_maps_cpu_n2e1,\n",
    "        diff_activation_maps_cpu_n2e1,\n",
    "        ori_activation_maps_cpu_n4e1, opt_activation_maps_cpu_n4e1,\n",
    "        diff_activation_maps_cpu_n4e1)\n",
    "    # imgs\n",
    "    save_imgs_path = os.path.join(\"../../../saved/pack/\", exp, \n",
    "                                  \"concat.png\")\n",
    "    concated_imgs.save(save_imgs_path)\n",
    "    # fms \n",
    "    save_fms_path = os.path.join(\"../../../saved/pack/\", exp, \n",
    "                                  \"concat_fms.png\")\n",
    "    concated_fms.save(save_fms_path)\n",
    "    # imgs & fms\n",
    "    save_imgs_fms_path = os.path.join(\"../../../saved/pack/\", exp, \n",
    "                                      \"concat_imgs_fms.png\")\n",
    "    concated_imgs_fms.save(save_imgs_fms_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T09:46:12.332114Z",
     "start_time": "2020-06-13T09:46:12.313173Z"
    }
   },
   "outputs": [],
   "source": [
    "# excel_path = \"Single.xlsx\"\n",
    "excel_path = \"Batches.xlsx\"\n",
    "sheet = \"950\"\n",
    "# sheet = \"Others\"\n",
    "excepts = [\"052148\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-13T09:46:11.355Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> RUN  052490 1 16 950\n",
      "=> class index: 950\n",
      "Only Keep 1th layers before.\n",
      "Resume from model from exp: 037 at epoch 0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "             VGG16-3         [-1, 64, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 73.50\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 74.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "xlsx = pd.ExcelFile(excel_path)\n",
    "excel = pd.read_excel(xlsx, sheet, Sdtype={\"exp\": str, \n",
    "                                           \"selected_layer\": int,\n",
    "                                           \"selected_filter\": int, \n",
    "                                           \"class_index\": int}).values\n",
    "for data in excel:\n",
    "    exp, selected_layer, selected_filter, class_index = data[0], data[1], \\\n",
    "        data[2], data[3]\n",
    "    exp = exp.replace(\"x\", \"\")\n",
    "    if exp in excepts:\n",
    "        print(\"=> Skip\")\n",
    "    else:\n",
    "        print(\"=> RUN \", exp, selected_layer, selected_filter, class_index)\n",
    "        main(exp, selected_layer, selected_filter, class_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "829px",
    "left": "10px",
    "top": "150px",
    "width": "283.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "258px",
    "left": "1439px",
    "right": "20px",
    "top": "120px",
    "width": "333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
