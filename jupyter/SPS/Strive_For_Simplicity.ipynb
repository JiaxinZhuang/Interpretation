{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:23:44.928236Z",
     "start_time": "2020-09-05T03:23:44.908287Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:23:45.884354Z",
     "start_time": "2020-09-05T03:23:44.929748Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms                                                                                                                                        \n",
    "from torchvision import models\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 600\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../extra/pytorch-cnn-visualizations/src\")\n",
    "import deep_dream\n",
    "\n",
    "sys.path.append(\"../../src/\")\n",
    "sys.path.append(\"../\")\n",
    "from datasets import imagenet\n",
    "\n",
    "from layer_activation_with_guided_backprop import GuidedBackprop\n",
    "from misc_functions import save_gradient_images\n",
    "from aux.utils import obtain_features_map, load_imgs, zscore, extract_valid\n",
    "from aux.visualization import visualize_features_map\n",
    "from aux.visualization import visualize_features_map_for_comparision\n",
    "from utils.visualizations.visualize import concat_imgs, preprocess_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:23:45.903168Z",
     "start_time": "2020-09-05T03:23:45.885607Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(exp, cnn_layer, filter_pos, class_index, device):\n",
    "    num_class = 30\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    train_transform = transforms.Compose([                                                                                                                                \n",
    "        transforms.Resize((224, 224), interpolation=Image.BILINEAR),                                                                                              \n",
    "        transforms.ToTensor(),                                                                                                                                            \n",
    "        #transforms.Normalize(mean, std)                                                                                                                                   \n",
    "           ])         \n",
    "    trainset = imagenet.ImageNet(root=\"/media/lincolnzjx/HardDisk/Datasets/\", \n",
    "                                 is_train=True, transform=train_transform)\n",
    "    \n",
    "    trainset.set_data([class_index], num_class)\n",
    "    imgs_path = []                                                                                                                                                            \n",
    "    images = []\n",
    "    labels = []\n",
    "    for img, label, img_path in trainset:                                                                                                                                     \n",
    "        images.append(img.unsqueeze(0))                                                                                                                                       \n",
    "        labels.append(label)                                                                                                                                                  \n",
    "        imgs_path.append(img_path)  \n",
    "        \n",
    "        \n",
    "    save_dir = \"./generated/\"\n",
    "    ################### Hyper-Parameter #######################\n",
    "    # exp = resume_exp\n",
    "    # epoch = resume_epoch\n",
    "    ##########################################################\n",
    "    ab_path = os.path.join(save_dir, exp)\n",
    "    \n",
    "    index2image = {index: item.split(\"/\")[-1].split(\".\")[0] for index, item in enumerate(imgs_path)}\n",
    "    index2image\n",
    "    \n",
    "    images_cpu = np.array([image.detach().clone().cpu().numpy().squeeze() for image in images])\n",
    "    \n",
    "    # Load image\n",
    "    # ext may be different.\n",
    "    #optimized_data, valid_imgs_path, valid_imgs_index = load_imgs(ab_path, imgs_path, non_exists_ok=True, ext=\".png\")\n",
    "    #valid_imgs, valid_labels = extract_valid(images, labels, valid_imgs_index)\n",
    "    #optimized_data_zscore = zscore(optimized_data, mean, std)\n",
    "    images_zscore = zscore(images_cpu, mean, std)\n",
    "    \n",
    "    # Move to device\n",
    "    # opt_image = torch.from_numpy(optimized_data_zscore).to(device)\n",
    "    original_image = torch.from_numpy(images_zscore).to(device)\n",
    "    prep_imgs = original_image\n",
    "    ## Create some need path\n",
    "    ################### Hyper-Parameter #######################\n",
    "    # exp = resume_exp\n",
    "    # epoch = resume_epoch\n",
    "    ##########################################################\n",
    "    index2image = {index: item.split(\"/\")[-1].split(\".\")[0] for index, item \n",
    "                   in enumerate(imgs_path)}\n",
    "    \n",
    "    \n",
    "    pretrained_model = models.vgg16(pretrained=True).to(device)\n",
    "    GBP = GuidedBackprop(pretrained_model) \n",
    "    \n",
    "    dir_path = os.path.join(save_dir, exp)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        \n",
    "    for prep_img, img_path in zip(prep_imgs, imgs_path):\n",
    "        prep_img = prep_img.unsqueeze(dim=0)\n",
    "        prep_img.requires_grad_(True)\n",
    "        guided_grads = GBP.generate_gradients(prep_img, None, cnn_layer, \n",
    "                                              filter_pos)\n",
    "        \n",
    "        name = img_path.split(\"/\")[-1].split(\".\")[0] + \".png\"\n",
    "        file_name_to_export = os.path.join(dir_path, \"GuidedBPcolor_\" + name)\n",
    "        save_gradient_images(guided_grads, file_name_to_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T10:30:09.372969Z",
     "start_time": "2020-07-29T10:30:09.362671Z"
    }
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:23:45.915582Z",
     "start_time": "2020-09-05T03:23:45.904207Z"
    }
   },
   "outputs": [],
   "source": [
    "excel_path = \"../analysis/week9/Batches.xlsx\"\n",
    "sheet = \"Others\"\n",
    "excepts = [\"052148\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:25:16.116790Z",
     "start_time": "2020-09-05T03:23:45.916460Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> RUN  052145 6 19 968\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052146 6 19 878\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052147 6 19 90\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> Skip\n",
      "=> RUN  052195 3 20 968\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052196 3 20 878\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052197 3 20 90\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052198 3 20 14\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052201 1 16 968\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052202 1 16 90\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052203 1 16 14\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052204 1 16 878\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052150 8 99 968\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052151 8 99 878\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052152 8 99 90\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052153 8 99 14\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052100 29 334 968\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../extra/pytorch-cnn-visualizations/src/misc_functions.py:47: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/Py36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2679\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2680\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<f4')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-57ee9c54a4c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             print(\"=> RUN \", exp, selected_layer, selected_filter, \n\u001b[1;32m     19\u001b[0m                   class_index)\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e417ddc30ad1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(exp, cnn_layer, filter_pos, class_index, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mfile_name_to_export\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GuidedBPcolor_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msave_gradient_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name_to_export\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Interpretation/extra/pytorch-cnn-visualizations/src/misc_functions.py\u001b[0m in \u001b[0;36msave_gradient_images\u001b[0;34m(gradient, file_name)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Save image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# path_to_file = os.path.join('../results', file_name + '.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Interpretation/extra/pytorch-cnn-visualizations/src/misc_functions.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(im, path)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_np_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Py36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2680\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f4"
     ]
    }
   ],
   "source": [
    "xlsx = pd.ExcelFile(excel_path)\n",
    "excel = pd.read_excel(xlsx, sheet, Sdtype={\"exp\": str, \n",
    "                                           \"selected_layer\": int,\n",
    "                                           \"selected_filter\": int, \n",
    "                                           \"class_index\": int,\n",
    "                                           \"Done\": str}).values\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for data in excel:\n",
    "    exp, selected_layer, selected_filter, class_index, done = data[0], data[1], \\\n",
    "        data[2], data[3], data[4]\n",
    "    exp = exp.replace(\"x\", \"\")\n",
    "    if exp in excepts:\n",
    "        print(\"=> Skip\")\n",
    "    else:\n",
    "        if done == \"N\":\n",
    "            print(\"=> RUN \", exp, selected_layer, selected_filter, \n",
    "                  class_index)\n",
    "            main(exp, selected_layer, selected_filter, class_index, device)\n",
    "            print(\"\")\n",
    "            print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T11:14:08.251572Z",
     "start_time": "2020-07-29T11:14:08.233951Z"
    }
   },
   "source": [
    "### 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:27:22.755565Z",
     "start_time": "2020-09-05T03:27:22.743341Z"
    }
   },
   "outputs": [],
   "source": [
    "excel_path = \"../analysis/week9/Batches.xlsx\"\n",
    "sheet = \"950\"\n",
    "excepts = [\"052148\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T03:29:14.168903Z",
     "start_time": "2020-09-05T03:27:23.163572Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> RUN  061300 1 16 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  052490 1 16 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7001 1 47 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7004 3 28 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  060490 3 20 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7005 6 19 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7006 8 99 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  70071 11 75 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  70081 13 91 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7009 15 173 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7010 18 49 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  060493 18 101 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7011 20 398 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7012 22 485 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  7013 25 1 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  060495 27 161 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  060496 29 334 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  071600 1 16 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n",
      "=> RUN  071601 3 20 950\n",
      "Len of new dataset is :30\n",
      "(30, 3, 224, 224)\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "xlsx = pd.ExcelFile(excel_path)\n",
    "excel = pd.read_excel(xlsx, sheet, Sdtype={\"exp\": str, \n",
    "                                           \"selected_layer\": int,\n",
    "                                           \"selected_filter\": int, \n",
    "                                           \"class_index\": int,\n",
    "                                           \"Done\": str}).values\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for data in excel:\n",
    "    exp, selected_layer, selected_filter, class_index, done = data[0], data[1], \\\n",
    "        data[2], data[3], data[4]\n",
    "    exp = exp.replace(\"x\", \"\")\n",
    "    if exp in excepts:\n",
    "        print(\"=> Skip\")\n",
    "    else:\n",
    "        if done == \"N\":\n",
    "            print(\"=> RUN \", exp, selected_layer, selected_filter, \n",
    "                  class_index)\n",
    "            main(exp, selected_layer, selected_filter, class_index, device)\n",
    "            print(\"\")\n",
    "            print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
