!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
AlexNet	src/model.py	/^class AlexNet(nn.Module):$/;"	c
Config	src/config.py	/^class Config:$/;"	c
DeepDreamLoss	src/loss.py	/^class DeepDreamLoss(nn.Module):$/;"	c
MNIST	src/dataset.py	/^class MNIST(Dataset):$/;"	c
Network	src/model.py	/^class Network(nn.Module):$/;"	c
__getitem__	src/dataset.py	/^    def __getitem__(self, index):$/;"	m	class:MNIST	file:
__init__	src/config.py	/^    def __init__(self):$/;"	m	class:Config
__init__	src/dataset.py	/^    def __init__(self, root, is_train, transform, input_size=224):$/;"	m	class:MNIST
__init__	src/loss.py	/^    def __init__(self, model, selected_layer, selected_filter):$/;"	m	class:DeepDreamLoss
__init__	src/model.py	/^    def __init__(self):$/;"	m	class:convNet
__init__	src/model.py	/^    def __init__(self, backbone="alxenet", num_classes=10, input_channel=1):$/;"	m	class:Network
__init__	src/model.py	/^    def __init__(self, num_classes, input_channel):$/;"	m	class:AlexNet
__len__	src/dataset.py	/^    def __len__(self):$/;"	m	class:MNIST	file:
_add_common_setting	src/config.py	/^    def _add_common_setting(self):$/;"	m	class:Config
_add_customized_setting	src/config.py	/^    def _add_customized_setting(self):$/;"	m	class:Config
_load_common_setting	src/config.py	/^    def _load_common_setting(self):$/;"	m	class:Config
_load_customized_setting	src/config.py	/^    def _load_customized_setting(self):$/;"	m	class:Config
_path_suitable_for_server	src/config.py	/^    def _path_suitable_for_server(self):$/;"	m	class:Config
_print	src/baseline.py	/^_print = init_logging(log_dir, exp).info$/;"	v
_print	src/trainer.py	/^_print = init_logging(log_dir, exp).info$/;"	v
acc	src/baseline.py	/^        acc = accuracy_score(y_true, y_pred)$/;"	v
acc	src/trainer.py	/^        acc = accuracy_score(y_true, y_pred)$/;"	v
backbone	src/baseline.py	/^backbone = configs_dict["backbone"]$/;"	v
backbone	src/trainer.py	/^backbone = configs_dict["backbone"]$/;"	v
batch_size	src/baseline.py	/^batch_size = configs_dict["batch_size"]$/;"	v
batch_size	src/trainer.py	/^batch_size = configs_dict["batch_size"]$/;"	v
betas	src/baseline.py	/^                           betas=(0.9, 0.999), eps=1e-08,$/;"	v
betas	src/trainer.py	/^                           betas=(0.9, 0.999), eps=1e-08,$/;"	v
ckpt	src/baseline.py	/^    ckpt = torch.load(resume_path)$/;"	v
ckpt	src/trainer.py	/^    ckpt = torch.load(resume_path)$/;"	v
configs	src/baseline.py	/^configs = config.Config()$/;"	v
configs	src/trainer.py	/^configs = config.Config()$/;"	v
configs_dict	src/baseline.py	/^configs_dict = configs.get_config()$/;"	v
configs_dict	src/trainer.py	/^configs_dict = configs.get_config()$/;"	v
convNet	src/model.py	/^class convNet(nn.Module):$/;"	c
criterion	src/baseline.py	/^criterion = nn.CrossEntropyLoss()$/;"	v
criterion	src/trainer.py	/^criterion = nn.CrossEntropyLoss()$/;"	v
cuda_id	src/baseline.py	/^cuda_id = configs_dict["cuda"]$/;"	v
cuda_id	src/trainer.py	/^cuda_id = configs_dict["cuda"]$/;"	v
data	src/baseline.py	/^            data = data.to(device)$/;"	v
data	src/trainer.py	/^            data = data.to(device)$/;"	v
dataset_name	src/baseline.py	/^dataset_name = configs_dict["dataset"]$/;"	v
dataset_name	src/trainer.py	/^dataset_name = configs_dict["dataset"]$/;"	v
desc	src/baseline.py	/^desc = "Exp-{}-Train".format(exp)$/;"	v
desc	src/trainer.py	/^desc = "Exp-{}-Train".format(exp)$/;"	v
device	src/baseline.py	/^device = torch.device("cuda" if torch.cuda.is_available() else "cpu")$/;"	v
device	src/trainer.py	/^device = torch.device("cuda" if torch.cuda.is_available() else "cpu")$/;"	v
ds	src/dataset.py	/^    ds = MNIST(root="..\/data", is_train=False, transform=transforms.ToTensor())$/;"	v
ds	src/dataset.py	/^    ds = MNIST(root="..\/data", is_train=True, transform=transforms.ToTensor())$/;"	v
eval_frequency	src/baseline.py	/^eval_frequency = configs_dict["eval_frequency"]$/;"	v
eval_frequency	src/trainer.py	/^eval_frequency = configs_dict["eval_frequency"]$/;"	v
exp	src/baseline.py	/^exp = configs_dict["experiment_index"]$/;"	v
exp	src/trainer.py	/^exp = configs_dict["experiment_index"]$/;"	v
format_np_output	src/utils/function.py	/^def format_np_output(np_arr):$/;"	f
forward	src/loss.py	/^    def forward(self, inputs):$/;"	m	class:DeepDreamLoss
forward	src/model.py	/^    def forward(self, inputs):$/;"	m	class:Network
forward	src/model.py	/^    def forward(self, x):$/;"	m	class:AlexNet
forward	src/model.py	/^    def forward(self, x):$/;"	m	class:convNet
get_config	src/config.py	/^    def get_config(self):$/;"	m	class:Config
hook_function	src/loss.py	/^        def hook_function(module, grad_in, grad_out):$/;"	f	function:DeepDreamLoss.hook_layer
hook_layer	src/loss.py	/^    def hook_layer(self):$/;"	m	class:DeepDreamLoss
im_as_var	src/utils/function.py	/^    im_as_var = preprocess_image(image, mean=mean, std=std)$/;"	v
image	src/utils/function.py	/^    image = Image.open("..\/..\/data\/example\/dd_tree.jpg").convert("RGB")$/;"	v
init_environment	src/utils/function.py	/^def init_environment(seed=0, cuda_id=0):$/;"	f
init_logging	src/utils/function.py	/^def init_logging(output_dir, exp):$/;"	f
input_size	src/baseline.py	/^input_size = configs_dict["input_size"]$/;"	v
input_size	src/trainer.py	/^input_size = configs_dict["input_size"]$/;"	v
learning_rate	src/baseline.py	/^learning_rate = configs_dict["learning_rate"]$/;"	v
learning_rate	src/trainer.py	/^learning_rate = configs_dict["learning_rate"]$/;"	v
log_dir	src/baseline.py	/^log_dir = configs_dict["log_dir"]$/;"	v
log_dir	src/trainer.py	/^log_dir = configs_dict["log_dir"]$/;"	v
loss	src/baseline.py	/^        loss = criterion(predict, target)$/;"	v
loss	src/trainer.py	/^        loss = criterion(predict, target)$/;"	v
losses	src/baseline.py	/^    losses = []$/;"	v
losses	src/trainer.py	/^    losses = []$/;"	v
mean	src/utils/function.py	/^    mean = [0.485, 0.456, 0.406]$/;"	v
model_dir	src/baseline.py	/^model_dir = configs_dict["model_dir"]$/;"	v
model_dir	src/trainer.py	/^model_dir = configs_dict["model_dir"]$/;"	v
model_path	src/baseline.py	/^            model_path = os.path.join(model_dir, str(exp), str(epoch))$/;"	v
model_path	src/trainer.py	/^            model_path = os.path.join(model_dir, str(exp), str(epoch))$/;"	v
n_epochs	src/baseline.py	/^n_epochs = configs_dict["n_epochs"]$/;"	v
n_epochs	src/trainer.py	/^n_epochs = configs_dict["n_epochs"]$/;"	v
net	src/baseline.py	/^net = model.Network(backbone=backbone)$/;"	v
net	src/model.py	/^    net = Network(backnone="alexnet")$/;"	v	class:convNet
net	src/trainer.py	/^net = model.Network(backbone=backbone)$/;"	v
net_state_dict	src/baseline.py	/^            net_state_dict = net.state_dict()$/;"	v
net_state_dict	src/trainer.py	/^            net_state_dict = net.state_dict()$/;"	v
num_workers	src/baseline.py	/^num_workers = configs_dict["num_workers"]$/;"	v
num_workers	src/trainer.py	/^num_workers = configs_dict["num_workers"]$/;"	v
opt	src/baseline.py	/^    opt = torch.optim.Adam(net.parameters(), lr=learning_rate,$/;"	v
opt	src/baseline.py	/^    opt = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)$/;"	v
opt	src/trainer.py	/^    opt = torch.optim.Adam(net.parameters(), lr=learning_rate,$/;"	v
opt	src/trainer.py	/^    opt = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)$/;"	v
optimizer	src/baseline.py	/^optimizer = configs_dict["optimizer"]$/;"	v
optimizer	src/trainer.py	/^optimizer = configs_dict["optimizer"]$/;"	v
predict	src/baseline.py	/^            predict = torch.argmax(net(data), dim=1).cpu().data.numpy()$/;"	v
predict	src/baseline.py	/^        predict = net(data)$/;"	v
predict	src/trainer.py	/^            predict = torch.argmax(net(data), dim=1).cpu().data.numpy()$/;"	v
predict	src/trainer.py	/^        predict = net(data)$/;"	v
preprocess_image	src/utils/function.py	/^def preprocess_image(pil_im, mean, std, resize=512, resize_im=True):$/;"	f
print_config	src/config.py	/^    def print_config(self, _print=None):$/;"	m	class:Config
print_model	src/model.py	/^    def print_model(self, input_size, device):$/;"	m	class:Network
re_size	src/baseline.py	/^re_size = configs_dict["re_size"]$/;"	v
re_size	src/trainer.py	/^re_size = configs_dict["re_size"]$/;"	v
recreate_im	src/utils/function.py	/^    recreate_im = recreate_image(im_as_var, reverse_mean, reverse_std)$/;"	v
recreate_image	src/utils/function.py	/^def recreate_image(im_as_var, reverse_mean, reverse_std):$/;"	f
resume	src/baseline.py	/^resume = configs_dict["resume"]$/;"	v
resume	src/trainer.py	/^resume = configs_dict["resume"]$/;"	v
resume_path	src/baseline.py	/^    resume_path = os.path.join(model_dir, str(exp), str(resume))$/;"	v
resume_path	src/trainer.py	/^    resume_path = os.path.join(model_dir, str(exp), str(resume))$/;"	v
reverse_mean	src/utils/function.py	/^    reverse_mean = [-0.485, -0.456, -0.406]$/;"	v
reverse_std	src/utils/function.py	/^    reverse_std = [1\/0.229, 1\/0.224, 1\/0.225]$/;"	v
rlimit	src/utils/function.py	/^rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)$/;"	v
save_image	src/utils/function.py	/^def save_image(im, path):$/;"	f
scheduler	src/baseline.py	/^scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau($/;"	v
scheduler	src/trainer.py	/^scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau($/;"	v
seed	src/baseline.py	/^seed = configs_dict["seed"]$/;"	v
seed	src/trainer.py	/^seed = configs_dict["seed"]$/;"	v
sota	src/baseline.py	/^sota = dict()$/;"	v
sota	src/trainer.py	/^sota = dict()$/;"	v
start_epoch	src/baseline.py	/^    start_epoch = resume + 1$/;"	v
start_epoch	src/baseline.py	/^start_epoch = 0$/;"	v
start_epoch	src/trainer.py	/^    start_epoch = resume + 1$/;"	v
start_epoch	src/trainer.py	/^start_epoch = 0$/;"	v
std	src/utils/function.py	/^    std = [0.229, 0.224, 0.225]$/;"	v
str2bool	src/utils/function.py	/^def str2bool(val):$/;"	f
target	src/baseline.py	/^            target = target.cpu().data.numpy()$/;"	v
target	src/trainer.py	/^            target = target.cpu().data.numpy()$/;"	v
tf_log	src/baseline.py	/^tf_log = os.path.join(log_dir, exp)$/;"	v
tf_log	src/trainer.py	/^tf_log = os.path.join(log_dir, exp)$/;"	v
threshold	src/baseline.py	/^            threshold=1e-4)$/;"	v
threshold	src/trainer.py	/^            threshold=1e-4)$/;"	v
train_avg_loss	src/baseline.py	/^    train_avg_loss = np.mean(losses)$/;"	v
train_avg_loss	src/trainer.py	/^    train_avg_loss = np.mean(losses)$/;"	v
train_transform	src/baseline.py	/^    train_transform = transforms.Compose([$/;"	v
train_transform	src/trainer.py	/^    train_transform = transforms.Compose([$/;"	v
trainloader	src/baseline.py	/^                                          shuffle=True, num_workers=num_workers)$/;"	v
trainloader	src/trainer.py	/^                                          shuffle=True, num_workers=num_workers)$/;"	v
trainset	src/baseline.py	/^    trainset = dataset.MNIST(root=".\/data\/", is_train=True, transform=train_transform)$/;"	v
trainset	src/trainer.py	/^    trainset = dataset.MNIST(root=".\/data\/", is_train=True, transform=train_transform)$/;"	v
val_transform	src/baseline.py	/^    val_transform = transforms.Compose([$/;"	v
val_transform	src/trainer.py	/^    val_transform = transforms.Compose([$/;"	v
valloader	src/baseline.py	/^                                        shuffle=False, num_workers=num_workers)$/;"	v
valloader	src/trainer.py	/^                                        shuffle=False, num_workers=num_workers)$/;"	v
valset	src/baseline.py	/^    valset = dataset.MNIST(root=".\/data\/", is_train=False, transform=val_transform)$/;"	v
valset	src/trainer.py	/^    valset = dataset.MNIST(root=".\/data\/", is_train=False, transform=val_transform)$/;"	v
writer	src/baseline.py	/^writer = SummaryWriter(log_dir=tf_log)$/;"	v
writer	src/trainer.py	/^writer = SummaryWriter(log_dir=tf_log)$/;"	v
y_pred	src/baseline.py	/^        y_pred = []$/;"	v
y_pred	src/trainer.py	/^        y_pred = []$/;"	v
y_true	src/baseline.py	/^        y_true = []$/;"	v
y_true	src/trainer.py	/^        y_true = []$/;"	v
